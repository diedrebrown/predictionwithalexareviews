{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_embedding\n",
      "  Using cached bert_embedding-1.0.1-py3-none-any.whl (13 kB)\n",
      "Processing /Users/diedrebrown/Library/Caches/pip/wheels/a6/41/8f/45bd1c58055d87aee5a71b6756a427ea8d92e506b3a9d17370/gluonnlp-0.6.0-py3-none-any.whl\n",
      "Collecting typing==3.6.6\n",
      "  Using cached typing-3.6.6-py3-none-any.whl (25 kB)\n",
      "Collecting mxnet==1.4.0\n",
      "  Using cached mxnet-1.4.0-cp37-cp37m-macosx_10_11_x86_64.whl (13.5 MB)\n",
      "Collecting numpy==1.14.6\n",
      "  Using cached numpy-1.14.6-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.4 MB)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/diedrebrown/opt/anaconda3/lib/python3.7/site-packages (from mxnet==1.4.0->bert_embedding) (2.24.0)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Using cached graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/diedrebrown/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/diedrebrown/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/diedrebrown/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/diedrebrown/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (2.8)\n",
      "Installing collected packages: numpy, gluonnlp, typing, graphviz, mxnet, bert-embedding\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.1\n",
      "    Uninstalling numpy-1.18.1:\n",
      "      Successfully uninstalled numpy-1.18.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.3.1 requires numpy<1.19.0,>=1.16.0, but you'll have numpy 1.14.6 which is incompatible.\n",
      "spacy 2.3.2 requires numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\n",
      "pandas 1.1.0 requires numpy>=1.15.4, but you'll have numpy 1.14.6 which is incompatible.\n",
      "numba 0.48.0 requires numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\n",
      "blis 0.4.1 requires numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\n",
      "astropy 4.0 requires numpy>=1.16, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "Successfully installed bert-embedding-1.0.1 gluonnlp-0.6.0 graphviz-0.8.4 mxnet-1.4.0 numpy-1.14.6 typing-3.6.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "sklearn.__version__>=\"0.20\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bert_embedding import BertEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-48cb18463b78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/df_train.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/df_test.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 5"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle(\"data/df_train.pickle\")\n",
    "test = pd.read_pickle(\"data/df_test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great speaker</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great little</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awesome</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great device</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6850</th>\n",
       "      <td>fun love</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>lot fun</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6852</th>\n",
       "      <td>buy gift husband problem set want return past ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>set control light home thermostat love able se...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>shame try friend excited try voice training he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  rating\n",
       "0                                         great speaker       3\n",
       "1                                          great little       4\n",
       "2                                               awesome       5\n",
       "3                                                  love       5\n",
       "4                                          great device       5\n",
       "...                                                 ...     ...\n",
       "6850                                           fun love       5\n",
       "6851                                            lot fun       5\n",
       "6852  buy gift husband problem set want return past ...       3\n",
       "6853  set control light home thermostat love able se...       5\n",
       "6854  shame try friend excited try voice training he...       2\n",
       "\n",
       "[6765 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random Forest + TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform reviews into features (TF-IDF encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom training data\n",
    "X = vectoriser.fit_transform(train['review'])\n",
    "y = train['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6765, 3625)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data\n",
    "X_test = vectoriser.transform(test['review'])\n",
    "y_test = test['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3039, 3625)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 15, None],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'class_weight': ['balanced'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:  3.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Create grid search object\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = model.predict(X_val)\n",
    "preds_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score:  0.9642\n",
      "Validation accuracy score:  0.7232\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy score: \", np.round(accuracy_score(y_train, preds_train), 4))\n",
    "print(\"Validation accuracy score: \", np.round(accuracy_score(y_val, preds_val), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score:  0.9646\n",
      "Validation F1 score:  0.6912\n"
     ]
    }
   ],
   "source": [
    "print(\"Training F1 score: \", np.round(f1_score(y_train, preds_train, average='weighted'), 4))\n",
    "print(\"Validation F1 score: \", np.round(f1_score(y_val, preds_val, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit the best model and predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
       "                       min_samples_split=6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the model on the full training set\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test set:  0.7206\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score on the test set: \", np.round(accuracy_score(y_test, preds_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on the test set:  0.6827\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score on the test set: \", np.round(f1_score(y_test, preds_test, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest + BERT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data transformed to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = pd.read_pickle(\"data/df_train_emb.pickle\")\n",
    "test_emb = pd.read_pickle('data/df_test_emb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.196070</td>\n",
       "      <td>-0.166101</td>\n",
       "      <td>0.088162</td>\n",
       "      <td>-0.387476</td>\n",
       "      <td>-0.075338</td>\n",
       "      <td>0.145149</td>\n",
       "      <td>-0.100961</td>\n",
       "      <td>0.332107</td>\n",
       "      <td>-0.399594</td>\n",
       "      <td>-0.577685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069991</td>\n",
       "      <td>-0.139178</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>-0.012614</td>\n",
       "      <td>0.167302</td>\n",
       "      <td>-0.074398</td>\n",
       "      <td>-0.048064</td>\n",
       "      <td>0.139034</td>\n",
       "      <td>-0.761326</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375143</td>\n",
       "      <td>0.252748</td>\n",
       "      <td>-0.009002</td>\n",
       "      <td>-0.047845</td>\n",
       "      <td>0.280493</td>\n",
       "      <td>0.355130</td>\n",
       "      <td>-0.615671</td>\n",
       "      <td>0.173091</td>\n",
       "      <td>-0.417215</td>\n",
       "      <td>-0.464209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238013</td>\n",
       "      <td>-0.144601</td>\n",
       "      <td>-0.116475</td>\n",
       "      <td>0.188066</td>\n",
       "      <td>-0.773876</td>\n",
       "      <td>-0.500712</td>\n",
       "      <td>0.129086</td>\n",
       "      <td>0.544737</td>\n",
       "      <td>-0.042861</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501979</td>\n",
       "      <td>-0.266838</td>\n",
       "      <td>-0.096103</td>\n",
       "      <td>-0.082397</td>\n",
       "      <td>0.593921</td>\n",
       "      <td>-0.378008</td>\n",
       "      <td>-0.344594</td>\n",
       "      <td>0.807677</td>\n",
       "      <td>-0.599734</td>\n",
       "      <td>-0.235689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477558</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>-0.362823</td>\n",
       "      <td>-0.148275</td>\n",
       "      <td>-0.017346</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.342333</td>\n",
       "      <td>0.486430</td>\n",
       "      <td>-0.301303</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.386490</td>\n",
       "      <td>0.361879</td>\n",
       "      <td>0.234233</td>\n",
       "      <td>-0.395798</td>\n",
       "      <td>0.935691</td>\n",
       "      <td>-0.320418</td>\n",
       "      <td>0.204268</td>\n",
       "      <td>0.338452</td>\n",
       "      <td>-0.052004</td>\n",
       "      <td>-0.810699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.915966</td>\n",
       "      <td>1.166752</td>\n",
       "      <td>-0.439389</td>\n",
       "      <td>0.048832</td>\n",
       "      <td>-0.294889</td>\n",
       "      <td>0.536690</td>\n",
       "      <td>-0.957577</td>\n",
       "      <td>-0.063262</td>\n",
       "      <td>-0.469560</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.209383</td>\n",
       "      <td>0.256669</td>\n",
       "      <td>0.263394</td>\n",
       "      <td>0.202036</td>\n",
       "      <td>0.686160</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.446947</td>\n",
       "      <td>0.150865</td>\n",
       "      <td>-0.399861</td>\n",
       "      <td>-0.683067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089460</td>\n",
       "      <td>-0.091926</td>\n",
       "      <td>-0.183906</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>-0.073143</td>\n",
       "      <td>0.375636</td>\n",
       "      <td>-0.353099</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>-0.477852</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6760</th>\n",
       "      <td>0.365414</td>\n",
       "      <td>-0.410754</td>\n",
       "      <td>0.485132</td>\n",
       "      <td>0.269432</td>\n",
       "      <td>0.485766</td>\n",
       "      <td>-0.270238</td>\n",
       "      <td>0.140317</td>\n",
       "      <td>0.333541</td>\n",
       "      <td>-0.844339</td>\n",
       "      <td>-0.108403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300737</td>\n",
       "      <td>0.121451</td>\n",
       "      <td>-0.393203</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>-0.273029</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>-0.113239</td>\n",
       "      <td>0.127719</td>\n",
       "      <td>-0.287914</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>0.707097</td>\n",
       "      <td>-0.112192</td>\n",
       "      <td>0.695348</td>\n",
       "      <td>0.372509</td>\n",
       "      <td>-0.000643</td>\n",
       "      <td>-0.696345</td>\n",
       "      <td>0.262589</td>\n",
       "      <td>0.827819</td>\n",
       "      <td>-0.913947</td>\n",
       "      <td>-0.246767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>-0.335931</td>\n",
       "      <td>-0.042181</td>\n",
       "      <td>-0.164755</td>\n",
       "      <td>-0.105138</td>\n",
       "      <td>0.244592</td>\n",
       "      <td>-0.068610</td>\n",
       "      <td>-0.113216</td>\n",
       "      <td>0.114406</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6762</th>\n",
       "      <td>0.008660</td>\n",
       "      <td>-0.460067</td>\n",
       "      <td>0.715946</td>\n",
       "      <td>-0.247391</td>\n",
       "      <td>0.500307</td>\n",
       "      <td>-0.152738</td>\n",
       "      <td>0.155582</td>\n",
       "      <td>0.342058</td>\n",
       "      <td>0.291900</td>\n",
       "      <td>-0.137198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.652499</td>\n",
       "      <td>0.539859</td>\n",
       "      <td>0.035297</td>\n",
       "      <td>-0.174948</td>\n",
       "      <td>0.150594</td>\n",
       "      <td>0.155599</td>\n",
       "      <td>-0.643417</td>\n",
       "      <td>-0.163756</td>\n",
       "      <td>-0.368232</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6763</th>\n",
       "      <td>0.348846</td>\n",
       "      <td>0.031631</td>\n",
       "      <td>0.840641</td>\n",
       "      <td>0.022863</td>\n",
       "      <td>0.702807</td>\n",
       "      <td>-0.170580</td>\n",
       "      <td>0.127256</td>\n",
       "      <td>-0.044578</td>\n",
       "      <td>0.135992</td>\n",
       "      <td>-0.475031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.768864</td>\n",
       "      <td>0.175243</td>\n",
       "      <td>0.024505</td>\n",
       "      <td>0.225648</td>\n",
       "      <td>0.357531</td>\n",
       "      <td>-0.172759</td>\n",
       "      <td>-0.444898</td>\n",
       "      <td>-0.230627</td>\n",
       "      <td>-0.244909</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6764</th>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.421485</td>\n",
       "      <td>-0.114266</td>\n",
       "      <td>0.242004</td>\n",
       "      <td>-0.192449</td>\n",
       "      <td>0.498682</td>\n",
       "      <td>-0.132391</td>\n",
       "      <td>0.257756</td>\n",
       "      <td>-0.279671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390895</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>-0.029889</td>\n",
       "      <td>0.562720</td>\n",
       "      <td>-0.143067</td>\n",
       "      <td>-0.224679</td>\n",
       "      <td>-0.194281</td>\n",
       "      <td>-0.294342</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6765 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.196070 -0.166101  0.088162 -0.387476 -0.075338  0.145149 -0.100961   \n",
       "1     0.375143  0.252748 -0.009002 -0.047845  0.280493  0.355130 -0.615671   \n",
       "2     0.501979 -0.266838 -0.096103 -0.082397  0.593921 -0.378008 -0.344594   \n",
       "3     0.386490  0.361879  0.234233 -0.395798  0.935691 -0.320418  0.204268   \n",
       "4    -0.209383  0.256669  0.263394  0.202036  0.686160 -0.000283 -0.446947   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6760  0.365414 -0.410754  0.485132  0.269432  0.485766 -0.270238  0.140317   \n",
       "6761  0.707097 -0.112192  0.695348  0.372509 -0.000643 -0.696345  0.262589   \n",
       "6762  0.008660 -0.460067  0.715946 -0.247391  0.500307 -0.152738  0.155582   \n",
       "6763  0.348846  0.031631  0.840641  0.022863  0.702807 -0.170580  0.127256   \n",
       "6764  0.317900  0.008619  0.421485 -0.114266  0.242004 -0.192449  0.498682   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0     0.332107 -0.399594 -0.577685  ... -0.069991 -0.139178  0.020440   \n",
       "1     0.173091 -0.417215 -0.464209  ...  0.238013 -0.144601 -0.116475   \n",
       "2     0.807677 -0.599734 -0.235689  ... -0.477558  0.225232 -0.362823   \n",
       "3     0.338452 -0.052004 -0.810699  ... -0.915966  1.166752 -0.439389   \n",
       "4     0.150865 -0.399861 -0.683067  ... -0.089460 -0.091926 -0.183906   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6760  0.333541 -0.844339 -0.108403  ... -0.300737  0.121451 -0.393203   \n",
       "6761  0.827819 -0.913947 -0.246767  ...  0.006230 -0.335931 -0.042181   \n",
       "6762  0.342058  0.291900 -0.137198  ... -0.652499  0.539859  0.035297   \n",
       "6763 -0.044578  0.135992 -0.475031  ... -0.768864  0.175243  0.024505   \n",
       "6764 -0.132391  0.257756 -0.279671  ... -0.390895  0.023549  0.012070   \n",
       "\n",
       "           762       763       764       765       766       767    y  \n",
       "0    -0.012614  0.167302 -0.074398 -0.048064  0.139034 -0.761326  3.0  \n",
       "1     0.188066 -0.773876 -0.500712  0.129086  0.544737 -0.042861  4.0  \n",
       "2    -0.148275 -0.017346  0.071473  0.342333  0.486430 -0.301303  5.0  \n",
       "3     0.048832 -0.294889  0.536690 -0.957577 -0.063262 -0.469560  5.0  \n",
       "4     0.479365 -0.073143  0.375636 -0.353099  0.043606 -0.477852  5.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "6760  0.184932 -0.273029  0.031431 -0.113239  0.127719 -0.287914  5.0  \n",
       "6761 -0.164755 -0.105138  0.244592 -0.068610 -0.113216  0.114406  4.0  \n",
       "6762 -0.174948  0.150594  0.155599 -0.643417 -0.163756 -0.368232  3.0  \n",
       "6763  0.225648  0.357531 -0.172759 -0.444898 -0.230627 -0.244909  NaN  \n",
       "6764 -0.029889  0.562720 -0.143067 -0.224679 -0.194281 -0.294342  5.0  \n",
       "\n",
       "[6765 rows x 769 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = train_emb.dropna(subset = ['y'])\n",
    "X_emb = train_emb.drop(columns = ['y'])\n",
    "y_emb = train_emb['y']\n",
    "\n",
    "test_emb = test_emb.dropna(subset = ['y'])\n",
    "X_emb_test = test_emb.drop(columns = ['y'])\n",
    "y_emb_test = test_emb['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make validation split\n",
    "X_train_emb, X_val_emb, y_train_emb, y_val_emb = train_test_split(X_emb, y_emb, test_size = 0.15, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed: 14.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Create grid search object\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train_emb, y_train_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = model.predict(X_val_emb)\n",
    "preds_train = model.predict(X_train_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score:  0.8369\n",
      "Validation accuracy score:  0.5399\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy score: \", np.round(accuracy_score(y_train_emb, preds_train), 4))\n",
    "print(\"Validation accuracy score: \", np.round(accuracy_score(y_val_emb, preds_val), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score:  0.8492\n",
      "Validation F1 score:  0.4818\n"
     ]
    }
   ],
   "source": [
    "print(\"Training F1 score: \", np.round(f1_score(y_train_emb, preds_train, average='weighted'), 4))\n",
    "print(\"Validation F1 score: \", np.round(f1_score(y_val_emb, preds_val, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit the best model and predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features='sqrt',\n",
       "                       n_estimators=50)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the model on the full training set\n",
    "model.fit(X_emb, y_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test set:  0.6472\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score on the test set: \", np.round(accuracy_score(y_emb_test, preds_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on the test set:  0.5867\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score on the test set: \", np.round(f1_score(y_emb_test, preds_test, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

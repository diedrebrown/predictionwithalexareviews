{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting User Satisfaction with Amazon Alexa\n",
    "## Random Forest + TF-IDF vs. BERT encoding for the Star Rating Prediction \n",
    "### By Elena Korshakova and Diedre Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the performance of the TF-IDF encoding method with the BERT encoding method in combination with the ensemble model such as random forest. We aim to compare the performance of different encoding methods based on the accuracy and F-1 score because ratings were unbalanced (skewed towards 5-star score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bert_embedding import BertEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"data/df_train.pickle\")\n",
    "test = pd.read_pickle(\"data/df_test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great speaker</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great little</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awesome</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great device</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6850</th>\n",
       "      <td>fun love</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>lot fun</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6852</th>\n",
       "      <td>buy gift husband problem set want return past ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>set control light home thermostat love able se...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>shame try friend excited try voice training he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  rating\n",
       "0                                         great speaker       3\n",
       "1                                          great little       4\n",
       "2                                               awesome       5\n",
       "3                                                  love       5\n",
       "4                                          great device       5\n",
       "...                                                 ...     ...\n",
       "6850                                           fun love       5\n",
       "6851                                            lot fun       5\n",
       "6852  buy gift husband problem set want return past ...       3\n",
       "6853  set control light home thermostat love able se...       5\n",
       "6854  shame try friend excited try voice training he...       2\n",
       "\n",
       "[6765 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random Forest + TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform reviews into features (TF-IDF encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started to transform the reviews into features using the TF-IDF as term-weighting method intended to reflect how important a word is in the review. In our case the TF–IDF value increases proportionally to the number of times a word appears in the review and is offset by the number of reviews in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom training data\n",
    "X = vectoriser.fit_transform(train['review'])\n",
    "y = train['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6765, 3625)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data\n",
    "X_test = vectoriser.transform(test['review'])\n",
    "y_test = test['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3039, 3625)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the best paremetrs for our data we started with the hyperparametr tuning using GridSearchCV to evaluate all the possible combinations of parameter values and retain the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 15, None],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'class_weight': ['balanced'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:  3.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Create grid search object\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = model.predict(X_val)\n",
    "preds_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score:  0.9642\n",
      "Validation accuracy score:  0.7232\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy score: \", np.round(accuracy_score(y_train, preds_train), 4))\n",
    "print(\"Validation accuracy score: \", np.round(accuracy_score(y_val, preds_val), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score:  0.9646\n",
      "Validation F1 score:  0.6912\n"
     ]
    }
   ],
   "source": [
    "print(\"Training F1 score: \", np.round(f1_score(y_train, preds_train, average='weighted'), 4))\n",
    "print(\"Validation F1 score: \", np.round(f1_score(y_val, preds_val, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result we got 96% traning accuracy (F1=96%) and 72% validation accuracy (F1=69%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit the best model and predict on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the hyperparametr tuning results we refit the model on the 2017 dataset and predict on 2018 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
       "                       min_samples_split=6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the model on the full training set\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test set:  0.7206\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score on the test set: \", np.round(accuracy_score(y_test, preds_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on the test set:  0.6827\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score on the test set: \", np.round(f1_score(y_test, preds_test, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We` got 72% accuracy (F1=68) using TF-IDF encoding and random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest + BERT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step aims to increase the accuracy using BERT encoding method. BERT considers all the words of the input reviews simultaneously and then uses an attention mechanism to develop a contextual meaning of the words within each review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data transformed to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = pd.read_pickle(\"data/df_train_emb.pickle\")\n",
    "test_emb = pd.read_pickle('data/df_test_emb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.196070</td>\n",
       "      <td>-0.166101</td>\n",
       "      <td>0.088162</td>\n",
       "      <td>-0.387476</td>\n",
       "      <td>-0.075338</td>\n",
       "      <td>0.145149</td>\n",
       "      <td>-0.100961</td>\n",
       "      <td>0.332107</td>\n",
       "      <td>-0.399594</td>\n",
       "      <td>-0.577685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069991</td>\n",
       "      <td>-0.139178</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>-0.012614</td>\n",
       "      <td>0.167302</td>\n",
       "      <td>-0.074398</td>\n",
       "      <td>-0.048064</td>\n",
       "      <td>0.139034</td>\n",
       "      <td>-0.761326</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375143</td>\n",
       "      <td>0.252748</td>\n",
       "      <td>-0.009002</td>\n",
       "      <td>-0.047845</td>\n",
       "      <td>0.280493</td>\n",
       "      <td>0.355130</td>\n",
       "      <td>-0.615671</td>\n",
       "      <td>0.173091</td>\n",
       "      <td>-0.417215</td>\n",
       "      <td>-0.464209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238013</td>\n",
       "      <td>-0.144601</td>\n",
       "      <td>-0.116475</td>\n",
       "      <td>0.188066</td>\n",
       "      <td>-0.773876</td>\n",
       "      <td>-0.500712</td>\n",
       "      <td>0.129086</td>\n",
       "      <td>0.544737</td>\n",
       "      <td>-0.042861</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501979</td>\n",
       "      <td>-0.266838</td>\n",
       "      <td>-0.096103</td>\n",
       "      <td>-0.082397</td>\n",
       "      <td>0.593921</td>\n",
       "      <td>-0.378008</td>\n",
       "      <td>-0.344594</td>\n",
       "      <td>0.807677</td>\n",
       "      <td>-0.599734</td>\n",
       "      <td>-0.235689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477558</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>-0.362823</td>\n",
       "      <td>-0.148275</td>\n",
       "      <td>-0.017346</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.342333</td>\n",
       "      <td>0.486430</td>\n",
       "      <td>-0.301303</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.386490</td>\n",
       "      <td>0.361879</td>\n",
       "      <td>0.234233</td>\n",
       "      <td>-0.395798</td>\n",
       "      <td>0.935691</td>\n",
       "      <td>-0.320418</td>\n",
       "      <td>0.204268</td>\n",
       "      <td>0.338452</td>\n",
       "      <td>-0.052004</td>\n",
       "      <td>-0.810699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.915966</td>\n",
       "      <td>1.166752</td>\n",
       "      <td>-0.439389</td>\n",
       "      <td>0.048832</td>\n",
       "      <td>-0.294889</td>\n",
       "      <td>0.536690</td>\n",
       "      <td>-0.957577</td>\n",
       "      <td>-0.063262</td>\n",
       "      <td>-0.469560</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.209383</td>\n",
       "      <td>0.256669</td>\n",
       "      <td>0.263394</td>\n",
       "      <td>0.202036</td>\n",
       "      <td>0.686160</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.446947</td>\n",
       "      <td>0.150865</td>\n",
       "      <td>-0.399861</td>\n",
       "      <td>-0.683067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089460</td>\n",
       "      <td>-0.091926</td>\n",
       "      <td>-0.183906</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>-0.073143</td>\n",
       "      <td>0.375636</td>\n",
       "      <td>-0.353099</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>-0.477852</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6760</th>\n",
       "      <td>0.365414</td>\n",
       "      <td>-0.410754</td>\n",
       "      <td>0.485132</td>\n",
       "      <td>0.269432</td>\n",
       "      <td>0.485766</td>\n",
       "      <td>-0.270238</td>\n",
       "      <td>0.140317</td>\n",
       "      <td>0.333541</td>\n",
       "      <td>-0.844339</td>\n",
       "      <td>-0.108403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300737</td>\n",
       "      <td>0.121451</td>\n",
       "      <td>-0.393203</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>-0.273029</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>-0.113239</td>\n",
       "      <td>0.127719</td>\n",
       "      <td>-0.287914</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>0.707097</td>\n",
       "      <td>-0.112192</td>\n",
       "      <td>0.695348</td>\n",
       "      <td>0.372509</td>\n",
       "      <td>-0.000643</td>\n",
       "      <td>-0.696345</td>\n",
       "      <td>0.262589</td>\n",
       "      <td>0.827819</td>\n",
       "      <td>-0.913947</td>\n",
       "      <td>-0.246767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>-0.335931</td>\n",
       "      <td>-0.042181</td>\n",
       "      <td>-0.164755</td>\n",
       "      <td>-0.105138</td>\n",
       "      <td>0.244592</td>\n",
       "      <td>-0.068610</td>\n",
       "      <td>-0.113216</td>\n",
       "      <td>0.114406</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6762</th>\n",
       "      <td>0.008660</td>\n",
       "      <td>-0.460067</td>\n",
       "      <td>0.715946</td>\n",
       "      <td>-0.247391</td>\n",
       "      <td>0.500307</td>\n",
       "      <td>-0.152738</td>\n",
       "      <td>0.155582</td>\n",
       "      <td>0.342058</td>\n",
       "      <td>0.291900</td>\n",
       "      <td>-0.137198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.652499</td>\n",
       "      <td>0.539859</td>\n",
       "      <td>0.035297</td>\n",
       "      <td>-0.174948</td>\n",
       "      <td>0.150594</td>\n",
       "      <td>0.155599</td>\n",
       "      <td>-0.643417</td>\n",
       "      <td>-0.163756</td>\n",
       "      <td>-0.368232</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6763</th>\n",
       "      <td>0.348846</td>\n",
       "      <td>0.031631</td>\n",
       "      <td>0.840641</td>\n",
       "      <td>0.022863</td>\n",
       "      <td>0.702807</td>\n",
       "      <td>-0.170580</td>\n",
       "      <td>0.127256</td>\n",
       "      <td>-0.044578</td>\n",
       "      <td>0.135992</td>\n",
       "      <td>-0.475031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.768864</td>\n",
       "      <td>0.175243</td>\n",
       "      <td>0.024505</td>\n",
       "      <td>0.225648</td>\n",
       "      <td>0.357531</td>\n",
       "      <td>-0.172759</td>\n",
       "      <td>-0.444898</td>\n",
       "      <td>-0.230627</td>\n",
       "      <td>-0.244909</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6764</th>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.421485</td>\n",
       "      <td>-0.114266</td>\n",
       "      <td>0.242004</td>\n",
       "      <td>-0.192449</td>\n",
       "      <td>0.498682</td>\n",
       "      <td>-0.132391</td>\n",
       "      <td>0.257756</td>\n",
       "      <td>-0.279671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390895</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>-0.029889</td>\n",
       "      <td>0.562720</td>\n",
       "      <td>-0.143067</td>\n",
       "      <td>-0.224679</td>\n",
       "      <td>-0.194281</td>\n",
       "      <td>-0.294342</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6765 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.196070 -0.166101  0.088162 -0.387476 -0.075338  0.145149 -0.100961   \n",
       "1     0.375143  0.252748 -0.009002 -0.047845  0.280493  0.355130 -0.615671   \n",
       "2     0.501979 -0.266838 -0.096103 -0.082397  0.593921 -0.378008 -0.344594   \n",
       "3     0.386490  0.361879  0.234233 -0.395798  0.935691 -0.320418  0.204268   \n",
       "4    -0.209383  0.256669  0.263394  0.202036  0.686160 -0.000283 -0.446947   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6760  0.365414 -0.410754  0.485132  0.269432  0.485766 -0.270238  0.140317   \n",
       "6761  0.707097 -0.112192  0.695348  0.372509 -0.000643 -0.696345  0.262589   \n",
       "6762  0.008660 -0.460067  0.715946 -0.247391  0.500307 -0.152738  0.155582   \n",
       "6763  0.348846  0.031631  0.840641  0.022863  0.702807 -0.170580  0.127256   \n",
       "6764  0.317900  0.008619  0.421485 -0.114266  0.242004 -0.192449  0.498682   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0     0.332107 -0.399594 -0.577685  ... -0.069991 -0.139178  0.020440   \n",
       "1     0.173091 -0.417215 -0.464209  ...  0.238013 -0.144601 -0.116475   \n",
       "2     0.807677 -0.599734 -0.235689  ... -0.477558  0.225232 -0.362823   \n",
       "3     0.338452 -0.052004 -0.810699  ... -0.915966  1.166752 -0.439389   \n",
       "4     0.150865 -0.399861 -0.683067  ... -0.089460 -0.091926 -0.183906   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6760  0.333541 -0.844339 -0.108403  ... -0.300737  0.121451 -0.393203   \n",
       "6761  0.827819 -0.913947 -0.246767  ...  0.006230 -0.335931 -0.042181   \n",
       "6762  0.342058  0.291900 -0.137198  ... -0.652499  0.539859  0.035297   \n",
       "6763 -0.044578  0.135992 -0.475031  ... -0.768864  0.175243  0.024505   \n",
       "6764 -0.132391  0.257756 -0.279671  ... -0.390895  0.023549  0.012070   \n",
       "\n",
       "           762       763       764       765       766       767    y  \n",
       "0    -0.012614  0.167302 -0.074398 -0.048064  0.139034 -0.761326  3.0  \n",
       "1     0.188066 -0.773876 -0.500712  0.129086  0.544737 -0.042861  4.0  \n",
       "2    -0.148275 -0.017346  0.071473  0.342333  0.486430 -0.301303  5.0  \n",
       "3     0.048832 -0.294889  0.536690 -0.957577 -0.063262 -0.469560  5.0  \n",
       "4     0.479365 -0.073143  0.375636 -0.353099  0.043606 -0.477852  5.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "6760  0.184932 -0.273029  0.031431 -0.113239  0.127719 -0.287914  5.0  \n",
       "6761 -0.164755 -0.105138  0.244592 -0.068610 -0.113216  0.114406  4.0  \n",
       "6762 -0.174948  0.150594  0.155599 -0.643417 -0.163756 -0.368232  3.0  \n",
       "6763  0.225648  0.357531 -0.172759 -0.444898 -0.230627 -0.244909  NaN  \n",
       "6764 -0.029889  0.562720 -0.143067 -0.224679 -0.194281 -0.294342  5.0  \n",
       "\n",
       "[6765 rows x 769 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = train_emb.dropna(subset = ['y'])\n",
    "X_emb = train_emb.drop(columns = ['y'])\n",
    "y_emb = train_emb['y']\n",
    "\n",
    "test_emb = test_emb.dropna(subset = ['y'])\n",
    "X_emb_test = test_emb.drop(columns = ['y'])\n",
    "y_emb_test = test_emb['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using exactly the same schema for the logistic regression to compare encoding performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make validation split\n",
    "X_train_emb, X_val_emb, y_train_emb, y_val_emb = train_test_split(X_emb, y_emb, test_size = 0.15, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed: 14.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Create grid search object\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train_emb, y_train_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = model.predict(X_val_emb)\n",
    "preds_train = model.predict(X_train_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score:  0.8369\n",
      "Validation accuracy score:  0.5399\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy score: \", np.round(accuracy_score(y_train_emb, preds_train), 4))\n",
    "print(\"Validation accuracy score: \", np.round(accuracy_score(y_val_emb, preds_val), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score:  0.8492\n",
      "Validation F1 score:  0.4818\n"
     ]
    }
   ],
   "source": [
    "print(\"Training F1 score: \", np.round(f1_score(y_train_emb, preds_train, average='weighted'), 4))\n",
    "print(\"Validation F1 score: \", np.round(f1_score(y_val_emb, preds_val, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit the best model and predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features='sqrt',\n",
       "                       n_estimators=50)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the model on the full training set\n",
    "model.fit(X_emb, y_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test set:  0.6472\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score on the test set: \", np.round(accuracy_score(y_emb_test, preds_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on the test set:  0.5867\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score on the test set: \", np.round(f1_score(y_emb_test, preds_test, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result BERT embeddings didn't give a boost in performance and we got only 65% accuracy (F-1=59%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
